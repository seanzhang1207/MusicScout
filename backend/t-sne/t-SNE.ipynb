{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext wurlitzer\n",
    "\n",
    "from time import time\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "# Check eager execution is enabled\n",
    "print(tf.executing_eagerly())        # => True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit DATASET_PATH here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/sean/Storage/Datasets/Birp'\n",
    "\n",
    "MP3_PATH = join(DATASET_PATH, 'mp3')\n",
    "WAV_PATH = join(DATASET_PATH, 'wav')\n",
    "MSPEC_PATH = join(DATASET_PATH, 'melspecs')\n",
    "ZOOMED_PATH = join(DATASET_PATH, 'zoomed')\n",
    "FLAT_PATH = join(DATASET_PATH, 'flat')\n",
    "\n",
    "mp3_files = glob(join(MP3_PATH, '*.mp3'))\n",
    "wav_files = glob(join(WAV_PATH, '*.wav'))\n",
    "npy_files = glob(join(MSPEC_PATH, '*.npy'))\n",
    "zoomed_files = glob(join(ZOOMED_PATH, '*.npy'))\n",
    "flat_files = glob(join(FLAT_PATH, '*.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "This will create a N x 320000 matrix, with N being the number of songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for npy in flat_files:\n",
    "    data.append(np.load(npy))\n",
    "    \n",
    "X = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running PCA and t-SNE\n",
    "\n",
    "First we run PCA over the data to reduce the dimenionality to 100. This makes pairwise comparison in t-SNE much faster, while having minimal impact on the final result. \n",
    "\n",
    "t-SNE is run using MulticoreTSNE which generally performs better than the one in scikit_learn, even if there's only one core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "pca = PCA(n_components=100).fit_transform(X)\n",
    "print(\"PCA finished in {0:.2f} seconds.\".format(time() - start_time))\n",
    "\n",
    "start_time = time()\n",
    "embedded = TSNE(n_jobs=8, n_iter=3000, verbose=2).fit_transform(pca)\n",
    "# embedded = np.load('embedded.npy')\n",
    "print(\"t-SNE finished in {0:.2f} seconds.\".format(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.scatter(embedded[:, 0], embedded[:, 1])\n",
    "\n",
    "for i in range(len(embedded)):\n",
    "    plt.annotate(i, embedded[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (WIP) Maybe try clustering them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "clustering = DBSCAN(eps=1, min_samples=5, n_jobs=7).fit_predict(X)\n",
    "\n",
    "print(clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab a cluster that includes a song\n",
    "\n",
    "The above clustering code is not working yet. In the mean time, I wrote this simplified version of DBSCAN that starts on a song that you specify (`song_id`), and do a outward search based on a hop distance that you provide (`threshold`), until there are no more reachable songs or the desired cluster size (`max_num`) is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster(song_id, embedding, threshold=1, done=None, max_num=50):\n",
    "    song = embedding[song_id]\n",
    "    if done is None:\n",
    "        done = set()\n",
    "        \n",
    "    if len(done) > max_num:\n",
    "        return set()\n",
    "        \n",
    "    next_songs = []\n",
    "    \n",
    "    for i, other_song in enumerate(embedding):\n",
    "        if i == song_id or i in done:\n",
    "            continue\n",
    "        if np.linalg.norm(song - other_song) < threshold:\n",
    "            next_songs.append(i)\n",
    "            done.add(i)\n",
    "            break\n",
    "    \n",
    "    if len(next_songs) == 0:\n",
    "        return set()\n",
    "    for i in next_songs:\n",
    "        done = done.union(get_cluster(i, embedding, threshold=threshold, done=done, max_num=max_num))\n",
    "        \n",
    "    return done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually grab the songs in a cluster\n",
    "\n",
    "Point `WHERE_TO_PUT_SONGS` to your desired path. Set the other variables according to your choice. This code finds songs in a cluster that includes `STARTING_SONG` and *copies* them to `WHERE_TO_PUT_SONGS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "STARTING_SONG = 606\n",
    "MAX_NUM = 50\n",
    "THRESHOLD = 0.7\n",
    "WHERE_TO_PUT_SONGS = '/home/sean/Music'\n",
    "\n",
    "def find_song_file(i):\n",
    "    song_name = splitext(split(flat_files[i])[1])[0]\n",
    "    for song_path in wav_files:\n",
    "        if song_name in song_path:\n",
    "            return song_path\n",
    "        \n",
    "cluster = list(get_cluster(STARTING_SONG, embedded, max_num=MAX_NUM, threshold=THRESHOLD))\n",
    "\n",
    "print(\"Got\", len(cluster), \"songs.\")\n",
    "\n",
    "for i, song_id in enumerate(cluster):\n",
    "    song_path = find_song_file(song_id)\n",
    "    \n",
    "    subprocess.run(['cp', song_path, WHERE_TO_PUT_SONGS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export a CSV of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "f = open('embedded.csv', 'w')\n",
    "\n",
    "for i, v in enumerate(embedded):\n",
    "    print(i)\n",
    "    song_path = find_song_file(i)\n",
    "    song_name = splitext(split(song_path)[1])[0]\n",
    "    print(re.findall('[0-9][0-9][0-9] - (.+) - (.+)', song_name))\n",
    "    author, title = re.findall('[0-9][0-9][0-9] - (.+) - (.+)', song_name)[0]\n",
    "    line = \"{}, \\\"{}\\\", \\\"{}\\\", {}, {}\\n\".format(i, title, author, v[0], v[1])\n",
    "    f.write(line)\n",
    "    \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
